{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167f506-160e-43bd-969a-9322452611d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PPCA v1.0.5\n",
    "\n",
    "STEP 2: BUILDING CLASSIFICATION\n",
    "\n",
    "Author: Perez, Joan\n",
    "\n",
    "This script classifies OSM buildings into three types (0: Null, 1: residential or mixed-use, 2: non-residential) based on the 'building' \n",
    "attribute. It refines the classification by performing a spatial join with non-populated land use areas, assigning non-residential status\n",
    "to buildings within these areas. A Decision Tree Classifier, trained on morphometric indicators (e.g., area, perimeter, elongation), is \n",
    "then used to predict missing 'type' values. The output includes a new 'type_filled' variable that combines original and predicted values.\n",
    "\n",
    "Full description, metadata and output descriptions available here :\n",
    "https://github.com/perezjoan/Population-Potential-on-Catchment-Area---PPCA-Worldwide/tree/main\n",
    "\n",
    "Acknowledgement \n",
    "This resource was produced within the emc2 project, which is funded by ANR (France), FFG (Austria), MUR (Italy) and Vinnova (Sweden) under\n",
    "the Driving Urban Transition Partnership, which has been co-funded by the European Commission.\n",
    "\n",
    "License: Attribution-ShareAlike 4.0 International - CC-BY-SA-4.0 license\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf735c20-3fd0-4ae7-84a0-3fad75aecb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################################\n",
    "\n",
    "# 0.1 : Box to fil with informations\n",
    "\n",
    "# Name of the case study. Expected format : Name = 'Nice'\n",
    "Name = \n",
    "\n",
    "# Ratio of data to subset for training the model (Run Appendix A.4 after 0.3 to help select/correct the ratio). \n",
    "# Expected format : Training_ratio = 0.7\n",
    "Training_ratio = \n",
    "\n",
    "###########################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63838b84-bf10-471d-8869-79ed4951dd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2 : libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# 0.3 Data preparation\n",
    "print(\"Step 0.3: Preparing data\")\n",
    "gpkg = f'PPCA_1-2_{Name}_retained.gpkg'\n",
    "non_populated_areas = gpd.read_file(gpkg, layer = 'osm_non_populated_areas')\n",
    "all_building = gpd.read_file(gpkg, layer = 'osm_building_filtered')\n",
    "\n",
    "## 1. ATTRIBUTE-BASED CLASSIFICATION OF BUILDING TYPE\n",
    "print(\"Step 1: Attribute-based classification of building type\")\n",
    "# 1.1 CLASSIFICATION USING OSM ATTRIBUTES\n",
    "# Define a function to determine the type based on the 'building' column (0 : NA ; 1 : residential or mixed-use ; 2 : non-residential)\n",
    "# Attribute values: https://wiki.openstreetmap.org/wiki/Key:building\n",
    "def assign_type(building_type):\n",
    "    if building_type == 'yes':\n",
    "        return 0\n",
    "    elif building_type in ['apartments', 'barracks', 'house', 'residential', 'bungalow', 'cabin', 'detached', 'dormitory', 'farm', 'static_caravan',\n",
    "                          'semidetached_house', 'stilt_house']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Add a new column 'type' and apply the conditions\n",
    "all_building.loc[:, 'type'] = all_building['building'].apply(assign_type)\n",
    "\n",
    "# 1.2 REFINED CLASSIFICATION\n",
    "# Spatial join with non-residential landuse areas\n",
    "joined_data = gpd.sjoin(all_building, non_populated_areas, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "# Buildings with Null in non-residential landuse areas are given the value 2 (non residential)\n",
    "joined_data.loc[(joined_data['type'] == 0) & joined_data['landuse'].notnull(), 'type'] = 2\n",
    "\n",
    "# Update 'type' to 2 if 'type' is 0 (NA) and at least one non-null value exists in the following columns : 'tourism', 'parking', 'shop' or 'office'\n",
    "condition = (joined_data['type'] == 0) & \\\n",
    "            (joined_data['tourism'].notnull() | \\\n",
    "             joined_data['parking'].notnull() | \\\n",
    "             joined_data['shop'].notnull() | \\\n",
    "             joined_data['office'].notnull())\n",
    "joined_data.loc[condition, 'type'] = 2\n",
    "\n",
    "## 2. DECISION TREE CLASSIFIER TO EVALUATE THE BUILDING TYPE\n",
    "print(\"Step 2: Decision tree classifier\")\n",
    "# 2.1 SUBSET DATA INTO TRAIN AND TEST DATA\n",
    "\n",
    "# List of columns to keep\n",
    "columns_to_keep = ['A', 'P', 'E', 'C', 'ECA', 'EA', 'SW', 'type']\n",
    "\n",
    "# Subset the DataFrame\n",
    "building_filtered = joined_data[columns_to_keep]\n",
    "\n",
    "# Subset the data where 'type' is 1 or 2\n",
    "building_res = building_filtered[building_filtered['type'].isin([1, 2])]\n",
    "\n",
    "# Subset the data where 'type' is 0\n",
    "building_null = building_filtered[building_filtered['type'] == 0]\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(45)\n",
    "\n",
    "# Create a boolean mask for selecting the data for training\n",
    "mask = np.random.rand(len(building_res)) < Training_ratio\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "data_train = building_res[mask]\n",
    "data_test = building_res[~mask]\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(f\"Training data shape: {data_train.shape}\")\n",
    "print(f\"Testing data shape: {data_test.shape}\")\n",
    "\n",
    "# 2.2 CALCULATE DECISION TREE CLASSIFIER & PRINT ACCURACY & PRECISION\n",
    "print(\"Step 2.2: Training decision tree classifier\")\n",
    "# Initialize the Decision Tree Classifier\n",
    "np.random.seed(45)\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Explicitly cast type to the appropriate data type before rounding and converting to categorical\n",
    "data_train = data_train.copy()\n",
    "data_test = data_test.copy()\n",
    "data_train['type'] = data_train['type'].astype(np.float64).round().astype('int32').astype('category')\n",
    "data_test['type'] = data_test['type'].astype(np.float64).round().astype('int32').astype('category')\n",
    "\n",
    "# Separate the target variable and features for the training set\n",
    "X_train = data_train.drop(columns=['type'])\n",
    "y_train = data_train['type']\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Separate the features and target variable for the test set\n",
    "X_test = data_test.drop(columns=['type'])\n",
    "y_test = data_test['type']\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on test data: {accuracy:.2f}\")\n",
    "\n",
    "# Calculate the precision for type = 1\n",
    "precision_type_1 = precision_score(y_test, y_pred, labels=[1], average='macro', zero_division=0)\n",
    "print(f\"Precision for type = 1 on test data: {precision_type_1:.2f}\")\n",
    "\n",
    "# Apply the model to building_null\n",
    "print(\"Step 2.2: Applying model to null values\")\n",
    "# Ensure that we are using the same features as those used during training\n",
    "X_null = building_null.drop(columns=['type'])\n",
    "\n",
    "# Make sure there are no additional columns\n",
    "X_null = X_null[X_train.columns]\n",
    "\n",
    "# Predict the types for building_null\n",
    "building_null = building_null.copy()\n",
    "building_null['type'] = clf.predict(X_null)\n",
    "\n",
    "# 2.3 APPLY THE TREE TO THE NULL VALUES\n",
    "print(\"Step 2.3: Applying tree to the entire dataset\")\n",
    "X_null = building_filtered.drop(columns=['type'])\n",
    "\n",
    "# Predict the types for building_null\n",
    "building_filtered = building_filtered.copy()  # Ensure we are working on a copy\n",
    "building_filtered.loc[:, 'type_pred'] = clf.predict(X_null)\n",
    "\n",
    "# Keep only one column from building_filtered\n",
    "type_pred = building_filtered[['type_pred']]\n",
    "\n",
    "# Concatenate along columns\n",
    "building_final = pd.concat([joined_data.reset_index(drop=True), type_pred.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Create the 'type_filled' column which take the non null values of building type, otherwise fill the null values with the model predictions\n",
    "building_final['type_filled'] = np.where(building_final['type'].isin([1, 2]), \n",
    "                                         building_final['type'], \n",
    "                                         building_final['type_pred'])\n",
    "print(f'Number of observations filled by DTS model: {len(building_null)}')\n",
    "print(\"Process complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b14a2-7469-4490-b9f2-579c9571a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################################\n",
    "\n",
    "## APPENDICES\n",
    "\n",
    "# A1. Save Outputs\n",
    "gpkg = f'PPCA_2-1_{Name}_TYPE.gpkg'\n",
    "building_final.to_file(gpkg, layer='osm_buildings_res_type', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650606c-9147-4501-85dc-7f2a0150f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2. Map & Statistics\n",
    "# Print the percentage and count of each building type\n",
    "feature_counts = joined_data['type'].value_counts()\n",
    "type_counts = joined_data['type'].value_counts(normalize=True) * 100\n",
    "print(\"Percentage and count of building types using attribute values, specialized columns & landuse\")\n",
    "for type_code, percentage in type_counts.items():\n",
    "    feature_count = feature_counts[type_code]\n",
    "    if type_code == 0:\n",
    "        print(f\"0 : Null: {percentage:.2f}% ({feature_count} buildings)\")\n",
    "    elif type_code == 1:\n",
    "        print(f\"1 : Residential or mixed-use: {percentage:.2f}% ({feature_count} buildings)\")\n",
    "    else:\n",
    "        print(f\"2 : Non-residential: {percentage:.2f}% ({feature_count} buildings)\")\n",
    "\n",
    "columns_to_drop = ['index_right', 'element_type_right', 'osmid_right', 'landuse']\n",
    "joined_data = joined_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Plot with custom colors\n",
    "colors = ['green', 'blue', 'red']\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "joined_data.plot(column='type', categorical=True, legend=True, ax=ax, cmap=ListedColormap(colors))\n",
    "legend_labels = ['0 - Null', '1 - Residential or mixed-use', '2 - Non-residential']\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colors[i], markersize=10) for i in range(len(colors))]\n",
    "ax.legend(handles, legend_labels, title='Building Type')\n",
    "plt.title('Distribution of Building Types : Classification based on Attributes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a669af-d6d1-4e75-b4dc-bcff6d806d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3. Tree Vizualization\n",
    "\n",
    "# Visualize the decision tree\n",
    "fig = plt.figure(figsize=(25, 20))\n",
    "_ = tree.plot_tree(clf, \n",
    "                   feature_names=X_train.columns,  \n",
    "                   class_names=['0', '1'],\n",
    "                   filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda7aa89-92f5-4625-8951-ddb65f7e52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A4. Map of residential buidlings filled by DTS\n",
    "\n",
    "# Print the percentage and count of each building type\n",
    "feature_counts = building_final['type_filled'].value_counts()\n",
    "type_counts = building_final['type_filled'].value_counts(normalize=True) * 100\n",
    "print(\"Percentage and count of building types using attribute values, specialized columns, landuse and DTS model\")\n",
    "for type_code, percentage in type_counts.items():\n",
    "    feature_count = feature_counts[type_code]\n",
    "    if type_code == 0:\n",
    "        print(f\"0 : NA: {percentage:.2f}% ({feature_count} buildings)\")\n",
    "    elif type_code == 1:\n",
    "        print(f\"1 : Residential or mixed-use: {percentage:.2f}% ({feature_count} buildings)\")\n",
    "    else:\n",
    "        print(f\"2 : Non-residential: {percentage:.2f}% ({feature_count} buildings)\")\n",
    "\n",
    "# Define custom colors\n",
    "colors = ['blue', 'red']\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "building_final.plot(column='type_filled', legend=False, ax=ax, cmap=ListedColormap(colors))\n",
    "\n",
    "# Add custom legend\n",
    "legend_labels = ['1 - Residential or mixed-use', '2 - Non-residential']\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colors[i], markersize=10) for i in range(len(colors))]\n",
    "ax.legend(handles, legend_labels, title='Building Type')\n",
    "\n",
    "# Add a title\n",
    "plt.title('Distribution of Building Types : Classification filled by DTS')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c0ff2-4569-471a-81aa-02e28bf3dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5. Compute Accuracy based on Trainning Data Size\n",
    "\n",
    "# Define the proportions for training data\n",
    "train_proportions = np.arange(0.01, 0.99, 0.01)\n",
    "\n",
    "# Lists to store proportions, accuracies, and precision for type = 1\n",
    "proportions_list = []\n",
    "accuracies_list = []\n",
    "precision_type_1_list = []\n",
    "\n",
    "# Loop over each training proportion\n",
    "for proportion in train_proportions:\n",
    "    # Set a random seed for reproducibility\n",
    "    np.random.seed(45)\n",
    "\n",
    "    # Create a boolean mask for selecting the proportion of the data for training\n",
    "    mask = np.random.rand(len(building_res)) < proportion\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    data_train = building_res[mask]\n",
    "    data_test = building_res[~mask]\n",
    "\n",
    "    # Initialize the Decision Tree Classifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "\n",
    "    # Separate the target variable and features for the training set\n",
    "    X_train = data_train.drop(columns=['type'])\n",
    "    y_train = data_train['type']\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Separate the features and target variable for the test set\n",
    "    X_test = data_test.drop(columns=['type'])\n",
    "    y_test = data_test['type']\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate precision for type = 1\n",
    "    precision_type_1 = precision_score(y_test, y_pred, labels=[1], average='macro', zero_division=0)\n",
    "\n",
    "    # Store the proportion, accuracy, and precision for type = 1\n",
    "    proportions_list.append(proportion)\n",
    "    accuracies_list.append(accuracy)\n",
    "    precision_type_1_list.append(precision_type_1)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(proportions_list, accuracies_list, marker='o', label='Accuracy')\n",
    "plt.plot(proportions_list, precision_type_1_list, marker='x', label='Precision for type = 1')\n",
    "plt.axvline(x=Training_ratio, color='green', linestyle='--', label=f'Training Ratio = {Training_ratio}')\n",
    "plt.title('Accuracy and Precision for type = 1 vs Training Data Proportion')\n",
    "plt.xlabel('Training Data Proportion')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
