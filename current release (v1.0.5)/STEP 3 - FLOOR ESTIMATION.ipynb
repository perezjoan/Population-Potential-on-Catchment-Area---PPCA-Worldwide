{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d30d6-27ed-4fc8-9ad9-08f1afbec808",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PPCA v1.0.4\n",
    "\n",
    "STEP 3: NUMBER OF FLOORS ESTIMATION\n",
    "\n",
    "Author: Perez, Joan \n",
    "\n",
    "This script processes residential and mixed-use OSM buildings ('type_filled' = 1) by filling missing values for building height and \n",
    "number of floors. It uses a Decision Tree Classifier to predict missing floor values ('FL') based on morphometric indicators like area,\n",
    "perimeter, and elongation. The floor-area ('FA') is recalculated using the predicted 'FL_filled' values.\n",
    "\n",
    "Full description, metadata and output descriptions available here :\n",
    "https://github.com/perezjoan/Population-Potential-on-Catchment-Area---PPCA-Worldwide/tree/main\n",
    "\n",
    "Acknowledgement\n",
    "This resource was produced within the emc2 project, which is funded by ANR (France), FFG (Austria), MUR (Italy) and Vinnova (Sweden) under\n",
    "the Driving Urban Transition Partnership, which has been co-funded by the European Commission.\n",
    "\n",
    "License: Attribution-ShareAlike 4.0 International - CC-BY-SA-4.0 license\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba08940e-54d3-4393-9078-84aca878f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################################\n",
    "\n",
    "# 0.1 : Box to fil with information\n",
    "\n",
    "# Name of the case study. Expected format : Name = 'Nice'\n",
    "Name = \n",
    "\n",
    "# Ratio of data to subset for training the model (Run Appendix A.3 to help selecting the ratio). \n",
    "# Expected format : Training_ratio = 0.7\n",
    "Training_ratio =\n",
    "\n",
    "###########################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c173219-076c-4233-9ecd-9f60df6b6f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2 : libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import libpysal\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# 0.3 Data preparation\n",
    "print(\"Step 0.3: Preparing data\")\n",
    "# Import OSM buildings\n",
    "gpkg = f'PPCA_2-1_{Name}_TYPE.gpkg'\n",
    "building = gpd.read_file(gpkg, layer = 'osm_buildings_res_type')\n",
    "building = building[building['type_filled'] == 1]\n",
    "\n",
    "## 1. DATA PREPARATION\n",
    "\n",
    "# 1.1 FILL & CALCULATE MISSING VALUES FOR HEIGHT & LEVEL\n",
    "print(\"Step 1: Fill height using level, fill level using height\")\n",
    "# Ensure height & level columns are numeric\n",
    "building['height'] = pd.to_numeric(building['height'], errors='coerce')\n",
    "building['building:levels'] = pd.to_numeric(building['building:levels'], errors='coerce')\n",
    "\n",
    "# checks if height is Null and if floor is non Null\n",
    "# If both conditions are met : multiplies the value of floor by 3 and assigns it to height\n",
    "building['height'] = building.apply(lambda row: row['building:levels'] * 3 if pd.isna(row['height'])\n",
    "                                     and not pd.isna(row['building:levels']) else row['height'], axis=1)\n",
    "\n",
    "# checks if the height observation is Null and if the floor is non Null\n",
    "# If both conditions are met : multiplies the value of floor by 3 and assigns it to height\n",
    "building['building:levels'] = building.apply(lambda row: round(row['height'] / 3) if pd.isna(row['building:levels'])\n",
    "                                             and not pd.isna(row['height']) else row['building:levels'], axis=1)\n",
    "\n",
    "# Calculate the number and percentage of rows with Null for both 'height' and 'building:levels'\n",
    "num_na = building[['height', 'building:levels']].isna().all(axis=1).sum()\n",
    "percent_na = (num_na / len(building)) * 100\n",
    "\n",
    "# Print the number and percentage of rows with NA for both columns\n",
    "print(f'{Name} : Number of remaining values with Null for height/floors: {num_na} ({percent_na:.2f}%)')\n",
    "\n",
    "# 1.2 ADD FLOOR-AREA RATIO TO LIST OF INDICATORS\n",
    "print(\"Step 1.2: Calculating floor-area ratio\")\n",
    "# Rename number of floors\n",
    "building.rename(columns={'building:levels': 'FL'}, inplace=True)\n",
    "\n",
    "# Floor area\n",
    "building['FA'] = building['FL'] * building['A']\n",
    "\n",
    "## 2. DECISION TREE CLASSIFIER TO EVALUATE THE MISSING NUMBER OF FLOORS\n",
    "print(\"Step 2: Decision tree classifier for missing floors\")\n",
    "# 2.1 SUBSET DATA INTO TRAIN AND TEST DATA\n",
    "\n",
    "# List of columns to keep\n",
    "columns_to_keep = ['A', 'P', 'E', 'C', 'FA', 'ECA', 'EA', 'SW', 'FL']\n",
    "\n",
    "# Subset the DataFrame\n",
    "building_filtered = building[columns_to_keep]\n",
    "\n",
    "# Create two subsets: one with non-null 'FL' and one with null 'FL'\n",
    "building_non_null = building_filtered[building_filtered['FL'].notnull()]\n",
    "building_null = building_filtered[building_filtered['FL'].isnull()]\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(45)\n",
    "\n",
    "# Create a boolean mask for selecting the data for training\n",
    "mask = np.random.rand(len(building_non_null)) < Training_ratio\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "data_train = building_non_null[mask]\n",
    "data_test = building_non_null[~mask]\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(f\"Training data shape - (observations, columns): {data_train.shape}\")\n",
    "print(f\"Testing data shape - (observations, columns): {data_test.shape}\")\n",
    "\n",
    "# 2.2 CALCULATE DECISION TREE CLASSIFIER & PRINT ACCURACY\n",
    "print(\"Step 2.2: Training decision tree classifier\")\n",
    "# Initialize the Decision Tree Classifier\n",
    "np.random.seed(45)\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Explicitly cast FL to float64 before rounding and converting to categorical\n",
    "data_train = data_train.copy()\n",
    "data_test = data_test.copy()\n",
    "data_train['FL'] = data_train['FL'].astype(np.float64).round().astype('int32').astype('category')\n",
    "data_test['FL'] = data_test['FL'].astype(np.float64).round().astype('int32').astype('category')\n",
    "\n",
    "# Separate the target variable and features for the training set\n",
    "X_train = data_train.drop(columns=['FL'])\n",
    "y_train = data_train['FL']\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Separate the features and target variable for the test set\n",
    "X_test = data_test.drop(columns=['FL'])\n",
    "y_test = data_test['FL']\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on test data: {accuracy:.2f}\")\n",
    "\n",
    "# Apply the model to building_null\n",
    "print(\"Step 2.2: Applying model to missing floor data\")\n",
    "# Ensure that we are using the same features as those used during training\n",
    "X_null = building_null.drop(columns=['FL'])\n",
    "\n",
    "# Make sure there are no additional columns\n",
    "X_null = X_null[X_train.columns]\n",
    "\n",
    "# Predict the types for building_null\n",
    "building_null = building_null.copy()\n",
    "building_null['FL'] = clf.predict(X_null)\n",
    "\n",
    "# 2.3 APPLY THE TREE TO THE NULL VALUES\n",
    "print(\"Step 2.3: Applying decision tree to the entire dataset\")\n",
    "X_null = building_filtered.drop(columns=['FL'])\n",
    "\n",
    "# Predict the types for building_null\n",
    "building_filtered = building_filtered.copy()  # Ensure we are working on a copy\n",
    "building_filtered.loc[:, 'FL_pred'] = clf.predict(X_null)\n",
    "\n",
    "# Keep only one column from building_filtered\n",
    "type_pred = building_filtered[['FL_pred']]\n",
    "\n",
    "# Concatenate along columns\n",
    "building_final = pd.concat([building.reset_index(drop=True), type_pred.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Create the 'type_filled' column which take the non null values of building type, otherwise fill the null values with the model predictions\n",
    "building_final['FL_filled'] = np.where(building_final['FL'].notna(), \n",
    "                                       building_final['FL'], \n",
    "                                       building_final['FL_pred'])\n",
    "\n",
    "# Correction of FA (floor-area) using 'FL_filled'\n",
    "building_final['FA'] = building_final['FL_filled'] * building_final['A']\n",
    "\n",
    "print(f'Number of observations filled by DTS model: {num_na}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151f1e3-91c6-4ce7-8042-512808a28bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################################\n",
    "\n",
    "## APPENDICES\n",
    "\n",
    "# A1. Save Outputs\n",
    "gpkg = f'PPCA_3-1_{Name}_IND_FL.gpkg'\n",
    "building_final.to_file(gpkg, layer='osm_buildings_FL_filled', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d981b2e-19b7-4ec8-a8c0-79987566ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A2. Map of Floor\n",
    "\n",
    "# Define custom colors\n",
    "colors = ['blue', 'red']\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "building[building['FL'].notna()].plot(ax=ax, color=colors[0], edgecolor=None, label='With FL')\n",
    "building[building['FL'].isna()].plot(ax=ax, color=colors[1], edgecolor=None, label='No FL')\n",
    "\n",
    "# Add custom legend\n",
    "legend_labels = ['Floor values', 'Null']\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colors[i], markersize=10) for i in range(len(colors))]\n",
    "ax.legend(handles, legend_labels, title='Building Type')\n",
    "\n",
    "# Set the title\n",
    "ax.set_title('Floor data : Available data vs Null')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4232f52-f824-4a69-8992-06039b2a4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A3. Tree Vizualization\n",
    "unique_classes = list(map(str, sorted(set(y_train))))\n",
    "\n",
    "# Visualize the decision tree\n",
    "def visualize_tree(clf, feature_names, class_names):\n",
    "    plt.figure(figsize=(25, 20))\n",
    "    tree.plot_tree(clf, \n",
    "                   feature_names=feature_names,  \n",
    "                   class_names=class_names,\n",
    "                   filled=True)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with the correct class names\n",
    "visualize_tree(clf, X_train.columns, unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5726e6-0f68-4dac-af3e-79fc6d21bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A4. Compute Accuracy based on trainning data size\n",
    "\n",
    "# Define the proportions for training data\n",
    "train_proportions = np.arange(0.01, 0.99, 0.01)\n",
    "\n",
    "# Lists to store proportions and accuracies\n",
    "proportions_list = []\n",
    "accuracies_list = []\n",
    "\n",
    "# Loop over each training proportion\n",
    "for proportion in train_proportions:\n",
    "    # Set a random seed for reproducibility\n",
    "    np.random.seed(45)\n",
    "\n",
    "    # Create a boolean mask for selecting the proportion of the data for training\n",
    "    mask = np.random.rand(len(building_non_null)) < proportion\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    data_train = building_non_null[mask]\n",
    "    data_test = building_non_null[~mask]\n",
    "\n",
    "    # Ensure the FL column is treated as categorical\n",
    "    data_train = data_train.copy()\n",
    "    data_test = data_test.copy()\n",
    "    \n",
    "    data_train['FL'] = data_train['FL'].astype(np.float64).round().astype(np.int32)\n",
    "    data_train['FL'] = data_train['FL'].astype('category')\n",
    "\n",
    "    data_test['FL'] = data_test['FL'].astype(np.float64).round().astype(np.int32)\n",
    "    data_test['FL'] = data_test['FL'].astype('category')\n",
    "\n",
    "    # Initialize the Decision Tree Classifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "\n",
    "    # Separate the target variable and features for the training set\n",
    "    X_train = data_train.drop(columns=['FL'])\n",
    "    y_train = data_train['FL']\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Separate the features and target variable for the test set\n",
    "    X_test = data_test.drop(columns=['FL'])\n",
    "    y_test = data_test['FL']\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Store the proportion and accuracy\n",
    "    proportions_list.append(proportion)\n",
    "    accuracies_list.append(accuracy)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(proportions_list, accuracies_list, marker='o', color='blue', label='Accuracy')\n",
    "\n",
    "# Adding a vertical line at Training_ratio\n",
    "plt.axvline(x=Training_ratio, color='green', linestyle='--', label=f'Training Ratio = {Training_ratio}')\n",
    "plt.title('Accuracy vs Training Data Proportion')\n",
    "plt.xlabel('Training Data Proportion')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1f610-b3b9-4b43-989b-ae7994fd7098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5. Map of floor filled by DTS\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cmap = plt.colormaps.get_cmap('magma_r')  # Use the reversed palette\n",
    "norm = mcolors.Normalize(vmin=building_final['FL_filled'].min(), vmax=building_final['FL_filled'].max())\n",
    "\n",
    "# Plot the buildings\n",
    "building_final.plot(column='FL_filled', ax=ax, legend=False, cmap=cmap, norm=norm, edgecolor=None)\n",
    "\n",
    "# Set the title\n",
    "ax.set_title('Building Floor Levels filled by DTS')\n",
    "\n",
    "# Add colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm._A = []\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "cbar.set_label('Floor Levels')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
